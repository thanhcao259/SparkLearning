{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataFrame\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPERATIONS ON DATAFRAME\n",
    "1. Reading file & Create data frame\n",
    "2. Checking Schema of dataframe\n",
    "3. Selecting columns and index\n",
    "4. Describe() method on dataframe\n",
    "5. Operation with column (add, drop, rename)\n",
    "6. Nested schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. READ THE CSV FILE WITH PYSPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order_df = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n",
    "#     .option(\"inferSchema\", \"true\") \\\n",
    "#     .load(\"data/student.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----+----+------+\n",
      "| id|      name|class|mark|gender|\n",
      "+---+----------+-----+----+------+\n",
      "|  1|  John Deo| Four|  75|female|\n",
      "|  2|  Max Ruin|Three|  85|  male|\n",
      "|  3|    Arnold|Three|  55|  male|\n",
      "|  4|Krish Star| Four|  60|female|\n",
      "|  5| John Mike| Four|  60|female|\n",
      "+---+----------+-----+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "order_df = spark.read.csv('data/student.csv', inferSchema=True, header=True)\n",
    "order_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1B. CREATE A DATAFRAME\n",
    "- Define structure/schema of dataframe\n",
    "- Create or load data\n",
    "- Create dataframe by createDataFrame(data= , schema= )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_data = [\n",
    "    (1,\"Alice\",\"3A\",80,\"female\"),\n",
    "    (2,\"Bob\",\"3A\",85,\"male\"),\n",
    "    (3,\"Cather\",\"3B\",90,\"female\"),\n",
    "    (4,\"Danny\",\"3B\",79,\"male\"),\n",
    "    (5,\"David\",\"3C\",68,\"male\"),\n",
    "    (6,\"Elle\",\"3A\",90,\"female\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1: Using StructType, StructField,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_1 = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"class\", StringType(), True),\n",
    "    StructField(\"mark\", IntegerType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df1 = spark.createDataFrame(data=demo_data, schema=schema_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+----+------+\n",
      "| id|  name|class|mark|gender|\n",
      "+---+------+-----+----+------+\n",
      "|  1| Alice|   3A|  80|female|\n",
      "|  2|   Bob|   3A|  85|  male|\n",
      "|  3|Cather|   3B|  90|female|\n",
      "|  4| Danny|   3B|  79|  male|\n",
      "|  5| David|   3C|  68|  male|\n",
      "|  6|  Elle|   3A|  90|female|\n",
      "+---+------+-----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2: Define schema by using string\n",
    "- \"<col_name> <data_type>, <col_name> <data_type>,...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_2 = \"id long, name string, class string, mark integer, gender string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df2= spark.createDataFrame(demo_data, schema_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+----+------+\n",
      "| id|  name|class|mark|gender|\n",
      "+---+------+-----+----+------+\n",
      "|  1| Alice|   3A|  80|female|\n",
      "|  2|   Bob|   3A|  85|  male|\n",
      "|  3|Cather|   3B|  90|female|\n",
      "|  4| Danny|   3B|  79|  male|\n",
      "|  5| David|   3C|  68|  male|\n",
      "|  6|  Elle|   3A|  90|female|\n",
      "+---+------+-----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 3: Define only list of Column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_3 = ['id', 'name','class','mark','gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df3 = spark.createDataFrame(demo_data, schema_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 4: Convert data from rdd to dataframe\n",
    "- Note: Must remove the header, unless err will happend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.textFile('data/student_no_header.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rdd)\n",
    "demo = rdd.take(4)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_data = rdd.map(lambda row: ( \n",
    "    int(row.split(',')[0]),\n",
    "    row.split(',')[1],\n",
    "    row.split(',')[2],\n",
    "    int(row.split(',')[3]),\n",
    "    row.split(',')[4]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'John Deo', 'Four', 75, 'female'), (2, 'Max Ruin', 'Three', 85, 'male')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df4 = spark.createDataFrame(convert_data, schema_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----+----+------+\n",
      "| id|      name|class|mark|gender|\n",
      "+---+----------+-----+----+------+\n",
      "|  1|  John Deo| Four|  75|female|\n",
      "|  2|  Max Ruin|Three|  85|  male|\n",
      "|  3|    Arnold|Three|  55|  male|\n",
      "|  4|Krish Star| Four|  60|female|\n",
      "|  5| John Mike| Four|  60|female|\n",
      "+---+----------+-----+----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_df4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- mark: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- mark: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- mark: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- mark: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_df1.printSchema()\n",
    "demo_df2.printSchema()\n",
    "demo_df3.printSchema()\n",
    "demo_df4.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. CHECKING SCHEMA OF DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- mark: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(order_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Selecting columns and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1, name='John Deo', class='Four', mark=75, gender='female'),\n",
       " Row(id=2, name='Max Ruin', class='Three', mark=85, gender='male'),\n",
       " Row(id=3, name='Arnold', class='Three', mark=55, gender='male')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order_df.head(number_of_rows)\n",
    "order_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'int'),\n",
       " ('name', 'string'),\n",
       " ('class', 'string'),\n",
       " ('mark', 'int'),\n",
       " ('gender', 'string')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check type of columns\n",
    "order_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, name: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_df.select([\"id\",\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|    name|\n",
      "+---+--------+\n",
      "|  1|John Deo|\n",
      "|  2|Max Ruin|\n",
      "|  3|  Arnold|\n",
      "+---+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_df.select([\"id\",\"name\"]).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Describe() method on dataframe\n",
    "\n",
    "- This method includes: count, min, max, stddev, mean and \n",
    "- operates on numberic - string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+---------+-----+------------------+------+\n",
      "|summary|                id|     name|class|              mark|gender|\n",
      "+-------+------------------+---------+-----+------------------+------+\n",
      "|  count|                35|       35|   35|                35|    35|\n",
      "|   mean|              18.0|     NULL| NULL| 74.65714285714286|  NULL|\n",
      "| stddev|10.246950765959598|     NULL| NULL|16.401116994139826|  NULL|\n",
      "|    min|                 1|Alex John|Eight|                18|female|\n",
      "|    max|                35|    Tumyu|Three|                96|  male|\n",
      "+-------+------------------+---------+-----+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Operating columns in data frame (add, drop, rename,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+----+------+\n",
      "| id|    name|class|mark|gender|\n",
      "+---+--------+-----+----+------+\n",
      "|  1|John Deo| Four|  75|female|\n",
      "|  2|Max Ruin|Three|  85|  male|\n",
      "|  3|  Arnold|Three|  55|  male|\n",
      "+---+--------+-----+----+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+----+------+-----+\n",
      "| id|    name|class|mark|gender|major|\n",
      "+---+--------+-----+----+------+-----+\n",
      "|  1|John Deo| Four|  75|female| Four|\n",
      "|  2|Max Ruin|Three|  85|  male|Three|\n",
      "|  3|  Arnold|Three|  55|  male|Three|\n",
      "+---+--------+-----+----+------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adding_df = order_df.withColumn('major', order_df['class'])\n",
    "adding_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+----+------+-----+----------+\n",
      "| id|    name|class|mark|gender|major|total_mark|\n",
      "+---+--------+-----+----+------+-----+----------+\n",
      "|  1|John Deo| Four|  75|female| Four|        95|\n",
      "|  2|Max Ruin|Three|  85|  male|Three|       105|\n",
      "|  3|  Arnold|Three|  55|  male|Three|        75|\n",
      "+---+--------+-----+----+------+-----+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adding_df = order_df.withColumns({'major':order_df['class'], \n",
    "                                  'total_mark':20+order_df['mark']})\n",
    "adding_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+----+------+\n",
      "| id|    name|class|mark|gender|\n",
      "+---+--------+-----+----+------+\n",
      "|  1|John Deo| Four|  75|female|\n",
      "|  2|Max Ruin|Three|  85|  male|\n",
      "|  3|  Arnold|Three|  55|  male|\n",
      "+---+--------+-----+----+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_df = adding_df.drop('major', 'total_mark')\n",
    "drop_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+----+------+-------+----------+\n",
      "| id|    name|class|mark|gender|major_2|total_mark|\n",
      "+---+--------+-----+----+------+-------+----------+\n",
      "|  1|John Deo| Four|  75|female|   Four|        95|\n",
      "|  2|Max Ruin|Three|  85|  male|  Three|       105|\n",
      "|  3|  Arnold|Three|  55|  male|  Three|        75|\n",
      "+---+--------+-----+----+------+-------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rename_df = adding_df.withColumnRenamed('major', 'major_2')\n",
    "rename_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+----+------+-------+-----+\n",
      "| id|    name|class|mark|gender|major_2|total|\n",
      "+---+--------+-----+----+------+-------+-----+\n",
      "|  1|John Deo| Four|  75|female|   Four|   95|\n",
      "|  2|Max Ruin|Three|  85|  male|  Three|  105|\n",
      "|  3|  Arnold|Three|  55|  male|  Three|   75|\n",
      "+---+--------+-----+----+------+-------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rename_df = adding_df.withColumnsRenamed({'major':'major_2', 'total_mark':'total'})\n",
    "rename_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Nested schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Nested schema').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = [\n",
    "    {'cust_id': 1, 'full_name': {'first_name': 'Alice', 'last_name': 'DE'}, 'city': 'Washington DC'},\n",
    "    {'cust_id': 2, 'full_name': {'first_name': 'Alice', 'last_name': 'DE'}, 'city': 'Washington DC'},\n",
    "    {'cust_id': 3, 'full_name': {'first_name': 'Alice', 'last_name': 'DE'}, 'city': 'Washington DC'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_schema = \"cust_id long, full_name struct<first_name: string, last_name: string>, city string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_schema2 = StructType([\n",
    "    StructField(name='cust_id', dataType=LongType(), nullable=False),\n",
    "    StructField('full_name', StructType([\n",
    "        StructField('first_name', StringType(),True), \n",
    "        StructField('last_name', StringType(), True)])),\n",
    "    StructField('city', StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_df1 = spark.createDataFrame(json_data, nest_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_df2 = spark.createDataFrame(json_data, nest_schema2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------+\n",
      "|cust_id|  full_name|         city|\n",
      "+-------+-----------+-------------+\n",
      "|      1|{Alice, DE}|Washington DC|\n",
      "|      2|{Alice, DE}|Washington DC|\n",
      "|      3|{Alice, DE}|Washington DC|\n",
      "+-------+-----------+-------------+\n",
      "\n",
      "+-------+-----------+-------------+\n",
      "|cust_id|  full_name|         city|\n",
      "+-------+-----------+-------------+\n",
      "|      1|{Alice, DE}|Washington DC|\n",
      "|      2|{Alice, DE}|Washington DC|\n",
      "|      3|{Alice, DE}|Washington DC|\n",
      "+-------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nested_df1.show()\n",
    "nested_df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cust_id: long (nullable = true)\n",
      " |-- full_name: struct (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- cust_id: long (nullable = false)\n",
      " |-- full_name: struct (nullable = true)\n",
      " |    |-- first_name: string (nullable = true)\n",
      " |    |-- last_name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nested_df1.printSchema()\n",
    "nested_df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df = spark.read.format('json').option('multiLine',True).option('header',True).load('data/customer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+----+--------------------------------------------------------------------+\n",
      "|address            |id |name|phone_numbers                                                       |\n",
      "+-------------------+---+----+--------------------------------------------------------------------+\n",
      "|{New York, NY}     |1  |John|[{123-456-7890, NULL, home, NULL}, {NULL, 987-654-3210, NULL, work}]|\n",
      "|{San Francisco, CA}|2  |Jane|[{555-1234, NULL, mobile, NULL}, {NULL, 777-4321, NULL, work}]      |\n",
      "+-------------------+---+----+--------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening data by explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['address', 'id', 'name', 'phone_numbers']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_df = cust_df.select('id', 'name', explode('phone_numbers').alias('phone'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+------------+\n",
      "| id|name|  type|      number|\n",
      "+---+----+------+------------+\n",
      "|  1|John|  home|123-456-7890|\n",
      "|  1|John|  work|987-654-3210|\n",
      "|  2|Jane|mobile|    555-1234|\n",
      "|  2|Jane|  work|    777-4321|\n",
      "+---+----+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flat_df.select('id','name','phone.type','phone.number').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
