{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySpark Handling Missing Values:\n",
    "1. Read file\n",
    "2. Drop missing rows using dropna()\n",
    "3. Fill missing values using fillna() + agg()\n",
    "4. Fill missing values using pyspark.ml.feature.Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Tuto 3 Handle Miss Value\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = spark.read.csv('data/test1.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+-------+\n",
      "|     Name| age|Experience| Salary|\n",
      "+---------+----+----------+-------+\n",
      "|    Krish|  31|      10.0|30000.0|\n",
      "|Sudhanshu|  30|       8.0|25000.0|\n",
      "|    Sunny|  29|       4.0|20000.0|\n",
      "|     Paul|  24|       3.0|20000.0|\n",
      "|   Harsha|  21|       1.0|15000.0|\n",
      "|  Shubham|  23|       2.0|18000.0|\n",
      "|   Mahesh|NULL|      NULL|40000.0|\n",
      "|     NULL|  34|      10.0|38000.0|\n",
      "|     NULL|  36|      NULL|   NULL|\n",
      "+---------+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Drop rows having null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dropna(how='any/all',\n",
    "    thresh=[int], subset=set/tuple/list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+-------+\n",
      "|     Name|age|Experience| Salary|\n",
      "+---------+---+----------+-------+\n",
      "|    Krish| 31|      10.0|30000.0|\n",
      "|Sudhanshu| 30|       8.0|25000.0|\n",
      "|    Sunny| 29|       4.0|20000.0|\n",
      "|     Paul| 24|       3.0|20000.0|\n",
      "|   Harsha| 21|       1.0|15000.0|\n",
      "|  Shubham| 23|       2.0|18000.0|\n",
      "+---------+---+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dropna_df = demo_df\n",
    "# dropna_df.dropna().show()\n",
    "dropna_df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+-------+\n",
      "|     Name| age|Experience| Salary|\n",
      "+---------+----+----------+-------+\n",
      "|    Krish|  31|      10.0|30000.0|\n",
      "|Sudhanshu|  30|       8.0|25000.0|\n",
      "|    Sunny|  29|       4.0|20000.0|\n",
      "|     Paul|  24|       3.0|20000.0|\n",
      "|   Harsha|  21|       1.0|15000.0|\n",
      "|  Shubham|  23|       2.0|18000.0|\n",
      "|   Mahesh|NULL|      NULL|40000.0|\n",
      "|     NULL|  34|      10.0|38000.0|\n",
      "+---------+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# thresh=x. Drop rows having less than x non-null values\n",
    "dropna_df.na.drop(how='any', thresh=2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Fill missing values\n",
    "- using fillna() with agg()\n",
    "- using imputing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame.fillna(value=[float/int/dict/str...], subset=set/tupe/list/col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_df = demo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill value =18 out the 'Age' column\n",
    "fill_df.fillna(value=18, subset='age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySpark.sql.functions inclues min/max/median/mean/last..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as pyf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_age = demo_df.select(\"*\")\\\n",
    "    .agg(pyf.min(demo_df['Age']))\\\n",
    "    .collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_name = demo_df.select('Name')\\\n",
    "    .agg(pyf.first(demo_df['Name']))\\\n",
    "    .collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_df.fillna(value=min_age).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_df.fillna({'Age':min_age, 'Name':first_name, 'Experience':5.0}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. pySpark.ml.feature.Imputer(\n",
    "- strategy='mean/median/mode', missingValue: float,\n",
    "- inputCols: [list/cols], outputCols: [list/cols],\n",
    "- inputCol: 'col', output: 'col'\n",
    "- relativeError: float = 0.001 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of each column on inputCols list\n",
    "# The mean value is stored on columns named 'inputCol_imputed'\n",
    "\n",
    "inputCols = ['Age','Experience','Salary']\n",
    "imputer = Imputer(strategy='mean', inputCols= inputCols,\n",
    "                  outputCols=[\"{}_imputed\".format(c) for c in inputCols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+-------+-----------+------------------+--------------+\n",
      "|     Name| Age|Experience| Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+---------+----+----------+-------+-----------+------------------+--------------+\n",
      "|    Krish|  31|      10.0|30000.0|         31|              10.0|       30000.0|\n",
      "|Sudhanshu|  30|       8.0|25000.0|         30|               8.0|       25000.0|\n",
      "|    Sunny|  29|       4.0|20000.0|         29|               4.0|       20000.0|\n",
      "|     Paul|  24|       3.0|20000.0|         24|               3.0|       20000.0|\n",
      "|   Harsha|  21|       1.0|15000.0|         21|               1.0|       15000.0|\n",
      "|  Shubham|  23|       2.0|18000.0|         23|               2.0|       18000.0|\n",
      "|   Mahesh|NULL|      NULL|40000.0|         28| 5.428571428571429|       40000.0|\n",
      "|     NULL|  34|      10.0|38000.0|         34|              10.0|       38000.0|\n",
      "|     NULL|  36|      NULL|   NULL|         36| 5.428571428571429|       25750.0|\n",
      "+---------+----+----------+-------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit() to calculate the mean of each column on dataframe\n",
    "# Output of fit() is stored by outputCols\n",
    "# transform() to replace those missing value with output of fit()\n",
    "imputed_df = imputer.fit(demo_df).transform(demo_df)\n",
    "imputed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df= imputed_df.fillna({'Name':first_name})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------------------+--------------+\n",
      "|     Name|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+---------+-----------+------------------+--------------+\n",
      "|    Krish|         31|              10.0|       30000.0|\n",
      "|Sudhanshu|         30|               8.0|       25000.0|\n",
      "|    Sunny|         29|               4.0|       20000.0|\n",
      "|     Paul|         24|               3.0|       20000.0|\n",
      "|   Harsha|         21|               1.0|       15000.0|\n",
      "|  Shubham|         23|               2.0|       18000.0|\n",
      "|   Mahesh|         28| 5.428571428571429|       40000.0|\n",
      "|    Krish|         34|              10.0|       38000.0|\n",
      "|    Krish|         36| 5.428571428571429|       25750.0|\n",
      "+---------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputed_df.drop('Age','Experience','Salary').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
